\begin{abstract}
TODO\\
In this project we would like to build a system that can quantify how well dyadic interviews go through.In order to achieve this, we will build several machine learning / statistical models trained on audio visual interview data along with
annotations and metadata with which we will analyse facial expressions such as smiles, prosody and the hold on language during interviews.We aim at generating detailed reports for interviews which tell how well the interview went with good reasoning (for interviewer) and how it couldâ€™ve been made better (for interviewee).
\end{abstract}
